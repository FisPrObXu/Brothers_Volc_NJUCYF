{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\nfrom pyvista import set_plot_theme\nset_plot_theme('document')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 1.1 -Basics of geological modeling with GemPy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing GemPy\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import gempy as gp\n\n# Importing auxiliary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\n# Setting options\nnp.random.seed(1515)\npd.set_option('precision', 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing and creating a set of input data\nThe data used for the construction of a model in GemPy is stored in\nPython objects. The main data classes are:\n\n::\n\n    -  Surface_points\n    -  Orientations\n    -  Grid\n    -  Surfaces\n    -  Series\n    -  Additional data\n    -  Faults\n\nWe will see each of this class in further detail in the future.\n\nMost of data can also be generated from raw data that comes in the form\nof CSV-files (CSV = comma-separated values). Such files might be\nattained by exporting model data from a different program such as\nGeoModeller or by simply creating it in spreadsheet software such as\nMicrosoft Excel or LibreOffice Calc.\n\nIn this tutorial, all input data is created by importing such CSV-files.\nThese exemplary files can be found in the ``input_data`` folder in the\nroot folder of GemPy. The data comprises $x$-, $y$- and\n$z$-positional values for all surface points and orientation\nmeasurements. For the latter, poles, azimuth and polarity are\nadditionally included. Surface points are furthermore assigned a\nformation. This might be a lithological unit such as \"Sandstone\" or a\nstructural feature such as \"Main Fault\". It is decisive to remember\nthat, in GemPy, interface position points mark the **bottom** of a\nlayer. If such points are needed to resemble a top of a formation (e.g.\nwhen modeling an intrusion), this can be achieved by defining a\nrespectively inverted orientation measurement.\n\nAs we generate our ``Data`` from CSV-files, we also have to define our\nmodel's real extent in $x$, $y$ and $z$, as well as\ndeclare a desired resolution for each axis. This resolution will in turn\ndetermine the number of voxels used during modeling. Here, we rely on a\nmedium resolution of 50x50x50, amounting to 125,000 voxels. The model\nextent should be chosen in a way that it contains all relevant data in a\nrepresentative space. As our model voxels are not cubes, but prisms, the\nresolution can take a different shape than the extent. We don't\nrecommend going much higher than 100 cells in every direction (1,000,000\nvoxels), as higher resolutions will become increasingly expensive to\ncompute.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model = gp.create_model('Tutorial_ch1_1_Basics')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'\n# Importing the data from CSV-files and setting extent and resolution\ngp.init_data(geo_model, [0, 2000., 0, 2000., 0, 750.], [50, 50, 50],\n             path_o=data_path + \"/data/input_data/getting_started/\"\n                                \"simple_fault_model_orientations.csv\",\n             path_i=data_path + \"/data/input_data/getting_started/\"\n                                \"simple_fault_model_points.csv\",\n             default_values=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.surfaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The input data can then be listed using the command ``get_data``. Note\nthat the order of formations and respective allocation to series is\nstill completely arbitrary. We will fix this in the following.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.get_data(geo_model, 'surface_points').head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.get_data(geo_model, 'orientations').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Declaring the sequential order of geological formations\n\n-  TODO update this section\n\nWe want our geological units to appear in the correct order relative to\nage. Such order might for example be given by a depositional sequence of\nstratigraphy, unconformities due to erosion or other lithological\ngenesis events such as igneous intrusions. A similar age-related order\nis to be declared for the faults in our model. In GemPy, the function\n``set_series`` is used to assign formations to different sequential\nseries via declaration in a Python dictionary.\n\nDefining the correct order of series is vital to the construction of the\nmodel! If you are using Python >3.6, the age-related order will already\nbe defined by the order of key entries, i.e. the first entry is the\nyoungest series, the last one the oldest. For older versions of Python,\nyou will have to specify the correct order as a separate list attribute\n\"``order_series``\\ \" (see cell below).\n\nYou can assign several surfaces to one series. The order of the units\nwithin such as series is only relevant for the color code, thus we\nrecommend to be consistent. You can define this order via another\nattribute \"``order_formations``/ \" or by using the specific command\n``set_order_formations``. (If the order of the pile differs from the\nfinal result the color of the interfaces and input data will be\ndifferent.)\n\nEvery fault is treated as an independent series and have to be at set at\nthe **top of the pile**. The relative order between the distinct faults\ndefines the tectonic relation between them (first entry is the\nyoungest).\n\nIn a model with simple sequential stratigraphy, all layer formations can\nbe assigned to one single series without a problem. All unit boundaries\nand their order would then be given by interface points. However, to\nmodel more complex lithostratigraphical relations and interactions, the\ndefinition of separate series becomes important. For example, you would\nneed to declare a \"newer\" series to model an unconformity or an\nintrusion that disturbs older stratigraphy.\n\nBy default we create a simple sequence inferred by the data:\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our example model comprises four main layers (plus an underlying\nbasement that is automatically generated by GemPy) and one main normal\nfault displacing those layers. Assuming a simple stratigraphy where each\nyounger unit was deposited onto the underlying older one, we can assign\nthese layer formations to one series called \"Strat\\_Series\". For the\nfault, we declare a respective \"Fault\\_Series\" as the first key entry in\nthe ``set_series`` dictionary. We could give any other names to these\nseries, the formations however have to be referred to as named in the\ninput data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.surfaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.map_stack_to_surfaces(geo_model,\n                         {\"Fault_Series\": 'Main_Fault',\n                          \"Strat_Series\": ('Sandstone_2', 'Siltstone',\n                                           'Shale', 'Sandstone_1', 'basement')},\n                         remove_unused_series=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.surfaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.set_is_fault(['Fault_Series'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.faults.faults_relations_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.faults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.faults.faults_relations_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Returning information from our input data\n\nOur model input data, here named \"*geo\\_model*\", contains all the\ninformation that is essential for the construction of our model. You can\naccess different types of information by using ``gp.get_data`` or simply\nby accessiong the atrribues.\n\nWe can, for example, return the coordinates of our modeling grid via:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As mentioned before, GemPy's core algorithm is based on interpolation of\ntwo types of data: - surface\\_points and - orientation measurements\n\n(if you want to know more on how this this interpolation algorithm\nworks, checkout our paper: https://www.geosci-model-dev.net/12/1/2019/gmd-12-1-2019.pdf).\n\nWe introduced the function ``get\\_data`` above. You can also specify which\nkind of data you want to call, by declaring the string attribute\n\"*dtype*\" to be either ``'surface_points'`` (interfaces) or ``'orientations'``\\ .\n\n### Interfaces Dataframe:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.get_data(geo_model, 'surface_points').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Orientations Dataframe:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.get_data(geo_model, 'orientations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that now all **surfaces** have been assigned to a **series** and\nare displayed in the correct order (from young to old).\n\n### Visualizing input data\n\nWe can also visualize our input data. This might for example be useful\nto check if all points and measurements are defined the way we want them\nto. Using the function ``plot_data``\\ , we attain a 2D projection of our\ndata points onto a plane of chosen *direction* (we can choose this\nattribute to be either $x$, $y$ or $z$).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot = gp.plot_2d(geo_model, show_lith=False, show_boundaries=False)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using ``plot_data_3D``\\ , we can also visualize this data in 3D. Note that\ndirect 3D visualization in GemPy requires `the Visualization\nToolkit <https://www.vtk.org/>`__ (VTK) to be installed.\n\nAll 3D plots in GemPy are interactive. This means that we can drag\nand drop any data point and measurement. The perpendicular axis views in\nVTK are particularly useful to move points solely on a desired 2D plane.\nAny changes will then be stored permanently in the \"InputData\"\ndataframe. If we want to reset our data points, we will then need to\nreload our original input data.\n\nExecuting the cell below will open a new window with a 3D interactive\nplot of our data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gpv = gp.plot_3d(geo_model, image=False, plotter_type='basic')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model generation\n\nOnce we have made sure that we have defined all our primary information\nas desired in our object ``DataManagement.InputData`` (named\n``geo_data`` in these tutorials), we can continue with the next step\ntowards creating our geological model: preparing the input data for\ninterpolation.\n\nThis is done by generating an ``InterpolatorData`` object (named\n``interp_data`` in these tutorials) from our ``InputData`` object via\nthe following function:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.set_interpolator(geo_model,\n                    compile_theano=True,\n                    theano_optimizer='fast_compile',\n                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function rescales the extent and coordinates of the original data\n(and store it in the attribute ``geo_data_res`` which behaves as a usual\n``InputData`` object) and adds mathematical parameters that are needed\nfor conducting the interpolation. The computation of this step may take\na while, as it also compiles a theano function which is required for the\nmodel computation. However, should this not be needed, we can skip it by\ndeclaring ``compile_theano = False`` in the function.\n\nFurthermore, this preparation process includes an assignment of numbers\nto each formation. Note that GemPy's always creates a default basement\nformation as the last formation number. Afterwards, numbers are\nallocated from youngest to oldest as defined by the sequence of series\nand formations. On the property ``formations`` on our interpolation\ndata, we can find out which number has been assigned to which formation:\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The parameters used for the interpolation can be returned using the\nfunction ``get_kriging_parameters``. These are generated automatically\nfrom the original data, but can be changed if needed. However, users\nshould be careful doing so, if they do not fully understand their\nsignificance.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.get_data(geo_model, 'kriging')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At this point, we have all we need to compute our full model via\n``compute_model``. By default, this will return two separate solutions\nin the form of arrays. The first gives information on the lithological\nformations, the second on the fault network in the model. These arrays\nconsist of two subarrays as entries each:\n\n1. Lithology block model solution:\n\n   -  Entry [0]: This array shows what kind of lithological formation is\n      found in each voxel, as indicated by a respective\n      formation\\_number.\n   -  Entry [1]: Potential field array that represents the orientation\n      of lithological units and layers in the block model.\n\n2. Fault network block model solution:\n\n   -  Entry [0]: Array in which all fault-separated areas of the model\n      are represented by a distinct number contained in each voxel.\n   -  Entry [1]: Potential field array related to the fault network in\n      the block model.\n\nBelow, we illustrate these different model solutions and how they can be\nused.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sol = gp.compute_model(geo_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Direct model visualization in GemPy\n\nModel solutions can be easily visualized in 2D sections in GemPy\ndirectly. Let's take a look at our lithology block:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.plot_2d(geo_model, show_data=True)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With ``cell_number=25`` and remembering that we defined our resolution\nto be 50 cells in each direction, we have chosen a section going through\nthe middle of our block. We have moved 25 cells in ``direction='y'``,\nthe plot thus depicts a plane parallel to the $x$- and\n$y$-axes. Setting ``plot_data=True``, we could plot original data\ntogether with the results. Changing the values for ``cell_number`` and\n``direction``, we can move through our 3D block model and explore it by\nlooking at different 2D planes.\n\nWe can do the same with out lithological scalar-field solution:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.plot_2d(geo_model, show_data=False, show_scalar=True, show_lith=False)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.plot_2d(geo_model, series_n=1, show_data=False, show_scalar=True, show_lith=False)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This illustrates well the fold-related deformation of the stratigraphy,\nas well as the way the layers are influenced by the fault.\n\nThe fault network modeling solutions can be visualized in the same way:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.solutions.scalar_field_at_surface_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.plot_2d(geo_model, show_block=True, show_lith=False)\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.plot_2d(geo_model, series_n=1, show_block=True, show_lith=False)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Marching cubes and vtk visualization\n\nIn addition to 2D sections we can extract surfaces to visualize in 3D\nrenderers. Surfaces can be visualized as 3D triangle complexes in VTK\n(see function plot\\_surfaces\\_3D below). To create these triangles, we\nneed to extract respective vertices and simplices from the potential\nfields of lithologies and faults. This process is automatized in GemPy\nwith the function ``get_surface``\\ .\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ver, sim = gp.get_surfaces(geo_model)\ngpv = gp.plot_3d(geo_model, image=False, plotter_type='basic')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the rescaled interpolation data, we can also run our 3D VTK\nvisualization in an interactive mode which allows us to alter and update\nour model in real time. Similarly to the interactive 3D visualization of\nour input data, the changes are permanently saved (in the\n``InterpolationInput.dataframe`` object). Additionally, the resulting changes\nin the geological models are re-computed in real time.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding topography\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.set_topography(d_z=(350, 750))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.compute_model(geo_model)\ngp.plot_2d(geo_model, show_topography=True)\nplt.show()\n\n\n# sphinx_gallery_thumbnail_number = 9\ngpv = gp.plot_3d(geo_model, plotter_type='basic', show_topography=True, show_surfaces=True,\n                 show_lith=True,\n                 image=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute at a given location\n\nThis is done by modifying the grid to a custom grid and recomputing.\nNotice that the results are given as *grid + surfaces\\_points\\_ref +\nsurface\\_points\\_rest locations*\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_i = np.array([[3, 5, 6]])\nsol = gp.compute_model(geo_model, at=x_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Therefore if we just want the value at **x\\_i**:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sol.custom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This return the id, and the scalar field values for each series\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save the model\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GemPy uses Python [pickle] for fast storing temporary objects\n(https://docs.python.org/3/library/pickle.html). However, module version\nconsistency is required. For loading a pickle into GemPy, you have to\nmake sure that you are using the same version of pickle and dependent\nmodules (e.g.: ``Pandas``, ``NumPy``) as were used when the data was\noriginally stored.\n\nFor long term-safer storage we can export the ``pandas.DataFrames`` to\ncsv by using:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.save_model(geo_model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}